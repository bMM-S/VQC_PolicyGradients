{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pennylane as qml \n",
    "import torch\n",
    "\n",
    "def create_circuit(n_qubits,n_layers=None,circ = \"simplified_two_design\",fim=False, shots=None):\n",
    "\n",
    "    dev = qml.device(\"default.qubit.torch\", wires=n_qubits, shots=shots)\n",
    "\n",
    "    def RZRY(params):\n",
    "        #qml.SpecialUnitary(params, wires=range(n_qubits))\n",
    "        #qml.SimplifiedTwoDesign(initial_layer_weights=init_params, weights=params, wires=range(n_qubits))\n",
    "        #qml.AngleEmbedding(params,wires=range(n_qubits))\n",
    "        for q in range(n_qubits):\n",
    "            qml.Hadamard(wires=q)\n",
    "\n",
    "        for w in range(n_layers): \n",
    "            for q in range(n_qubits):\n",
    "                index = w * (2*n_qubits) + q * 2\n",
    "                qml.RZ(params[index],wires=q)\n",
    "                qml.RY(params[index + 1],wires=q)\n",
    "        \n",
    "        qml.broadcast(qml.CNOT , wires=range(n_qubits), pattern=\"all_to_all\")\n",
    "        \n",
    "        return qml.probs(wires=range(n_qubits))\n",
    "\n",
    "    def S2D(init_params,params,measurement_qubits=0,prod_approx=False):\n",
    "        #qml.SpecialUnitary(params, wires=range(n_qubits))\n",
    "        qml.SimplifiedTwoDesign(initial_layer_weights=init_params, weights=params, wires=range(n_qubits))\n",
    "        \n",
    "        #qml.broadcast(qml.CNOT , wires=range(n_qubits), pattern=\"all_to_all\")\n",
    "        if not prod_approx:\n",
    "            return qml.probs(wires=list(range(measurement_qubits)))\n",
    "        else:\n",
    "            return [qml.probs(i) for i in range(measurement_qubits)]\n",
    "\n",
    "    def SU(params):\n",
    "        qml.SpecialUnitary(params, wires=range(n_qubits))\n",
    "        \n",
    "        ZZ = qml.operation.Tensor(qml.PauliZ(0), qml.PauliZ(1))\n",
    "        for i in range(2,n_qubits):\n",
    "            ZZ = qml.operation.Tensor(ZZ, qml.PauliZ(i))\n",
    "\n",
    "        return qml.expval(ZZ)\n",
    "    \n",
    "    def simmpleRZRY(params,cnots=True):\n",
    "        qml.broadcast(qml.Hadamard, wires=range(n_qubits), pattern=\"single\")\n",
    "        qml.broadcast(qml.RZ, wires=range(n_qubits), pattern=\"single\", parameters=params[0])\n",
    "        qml.broadcast(qml.RY, wires=range(n_qubits), pattern=\"single\", parameters=params[1])\n",
    "        if cnots:\n",
    "            qml.broadcast(qml.CNOT, wires=range(n_qubits), pattern=\"chain\")\n",
    "\n",
    "            return qml.expval(qml.PauliZ(n_qubits-1))\n",
    "        else:\n",
    "            ZZ = qml.operation.Tensor(qml.PauliZ(0), qml.PauliZ(1))\n",
    "            for i in range(2,n_qubits):\n",
    "                ZZ = qml.operation.Tensor(ZZ, qml.PauliZ(i))\n",
    "\n",
    "            return qml.expval(ZZ)\n",
    "        \n",
    "    def RY(params,y=True,probs=False,prod=False, entanglement=None):\n",
    "        #qml.broadcast(qml.Hadamard, wires=range(n_qubits), pattern=\"single\")\n",
    "        qml.broadcast(qml.RY, wires=range(n_qubits), pattern=\"single\", parameters=params)\n",
    "        #qml.broadcast(qml.CZ, wires=range(n_qubits), pattern=\"all_to_all\")\n",
    "\n",
    "        if entanglement==\"all_to_all\":\n",
    "            qml.broadcast(qml.CNOT, wires=range(n_qubits), pattern=\"all_to_all\")\n",
    "        \n",
    "        if y==True:\n",
    "            #YY = qml.operation.Tensor(qml.PauliY(0), qml.PauliY(1))\n",
    "            YY = [qml.PauliZ(0), qml.PauliZ(1)]\n",
    "            for i in range(2,n_qubits):\n",
    "                #YY = qml.operation.Tensor(YY, qml.PauliY(i))\n",
    "                YY.append(qml.PauliZ(i))\n",
    "            \n",
    "            #return [qml.expval(i) for i in YY]\n",
    "            return qml.expval(YY)\n",
    "\n",
    "        elif probs==False:\n",
    "\n",
    "            ZZ = qml.operation.Tensor(qml.PauliZ(0), qml.PauliZ(1))\n",
    "            #ZZ = [qml.PauliZ(0), qml.PauliZ(1)]\n",
    "            for i in range(2,n_qubits):\n",
    "                ZZ = qml.operation.Tensor(ZZ, qml.PauliZ(i))        \n",
    "                #ZZ.append(qml.PauliZ(i))        \n",
    "\n",
    "            #return [qml.expval(i) for i in ZZ]\n",
    "            return qml.expval(ZZ)\n",
    "\n",
    "        else:\n",
    "            if prod:\n",
    "                return [qml.probs(i) for i in range(n_qubits)]\n",
    "            else:\n",
    "                return qml.probs(wires=range(n_qubits))\n",
    "            \n",
    "        \n",
    "        \n",
    "    def GHZ(params,measurement_qubits=0):\n",
    "        qml.RY(params,wires=0)\n",
    "        qml.broadcast(qml.CNOT, wires=range(n_qubits), pattern=\"chain\")\n",
    "\n",
    "        return qml.probs(wires=range(measurement_qubits))\n",
    "\n",
    "    def random_product_state(params,gate_sequence=None):\n",
    "                \n",
    "        for i in range(n_qubits):\n",
    "            qml.RY(np.pi / 4, wires=i)\n",
    "\n",
    "        for ll in range(len(params)):\n",
    "\n",
    "            for i in range(n_qubits):\n",
    "                gate_sequence[\"{}{}\".format(ll,i)](params[ll][i], wires=i)\n",
    "\n",
    "            #for i in range(n_qubits - 1):\n",
    "                #qml.CZ(wires=[i, i + 1])\n",
    "    def SEL(params, measurement_qubits=0):\n",
    "        qml.StronglyEntanglingLayers(params, wires=range(n_qubits))\n",
    "        return qml.probs(wires=range(measurement_qubits))\n",
    "    \n",
    "    def RL(params, measurement_qubits=0):\n",
    "        qml.RandomLayers(params, ratio_imprim=0.8 ,imprimitive=qml.CZ, wires=range(n_qubits))\n",
    "        return qml.probs(wires=range(measurement_qubits))\n",
    "    \n",
    "    if circ == \"rzry\":\n",
    "        qcircuit = RZRY\n",
    "    elif circ == \"simplified_two_design\":\n",
    "        qcircuit = S2D\n",
    "    elif circ == \"special_unitary\":\n",
    "        qcircuit = SU\n",
    "    elif circ == \"simpleRZRY\":\n",
    "        qcircuit = simmpleRZRY\n",
    "    elif circ == \"RY\":\n",
    "        qcircuit = RY\n",
    "    elif circ == \"ghz\":\n",
    "        qcircuit = GHZ\n",
    "    elif circ == \"random_product_state\":\n",
    "        qcircuit = random_product_state\n",
    "    elif circ == \"SEL\":\n",
    "        qcircuit = SEL\n",
    "    elif circ == \"RL\":\n",
    "        qcircuit = RL\n",
    "    if not fim:\n",
    "        circuit = qml.QNode(qcircuit, dev,interface=\"torch\", diff_method=\"backprop\")\n",
    "    else:\n",
    "        circuit = qml.QNode(qcircuit, dev)\n",
    "\n",
    "    return circuit\n",
    "\n",
    "def compute_gradient(log_prob, w):\n",
    "    \"\"\"Compute gradient of the log probability with respect to weights.\n",
    "    \n",
    "    Args:\n",
    "    - log_prob (torch.Tensor): The log probability tensor.\n",
    "    - w (torch.Tensor): The weights tensor, with requires_grad=True.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The gradient of log_prob with respect to w, flattened.\n",
    "    \"\"\"\n",
    "    if w.grad is not None:\n",
    "        w.grad.zero_()\n",
    "    log_prob.backward(retain_graph=True)\n",
    "    \n",
    "    if w.grad is None:\n",
    "        raise ValueError(\"The gradient for the given log_prob with respect to w is None.\")\n",
    "    \n",
    "    return w.grad.view(-1).detach().numpy()\n",
    "\n",
    "def policy(probs, policy_type=\"contiguous-like\", n_actions=2, n_qubits=1):\n",
    "\n",
    "    if policy_type == \"contiguous-like\":\n",
    "        return probs\n",
    "    elif policy_type == \"parity-like\":\n",
    "        policy = torch.zeros(n_actions)\n",
    "        for i in range(len(probs)):\n",
    "            a=[]\n",
    "            for m in range(int(np.log2(n_actions))):\n",
    "                if m==0:    \n",
    "                    bitstring = np.binary_repr(i,width=n_qubits)\n",
    "                else:\n",
    "                    bitstring = np.binary_repr(i,width=n_qubits)[:-m]\n",
    "                \n",
    "                a.append(bitstring.count(\"1\") % 2)\n",
    "            policy[int(\"\".join(str(x) for x in a),2)] += probs[i]\n",
    "\n",
    "        return policy    \n",
    "    \n",
    "def compute_policy_and_gradient(args):\n",
    "    n_qubits, shapes, type , n_actions, policy_type, clamp = args\n",
    "\n",
    "    if policy_type == \"parity-like\":\n",
    "        measure_qubits = n_qubits\n",
    "    else:\n",
    "        measure_qubits = int(np.log2(n_actions))\n",
    "\n",
    "    qc = create_circuit(n_qubits, circ=type, fim=False, shots=None)\n",
    "\n",
    "    if type == \"simplified_two_design\":\n",
    "        weights = [np.random.uniform(-np.pi,np.pi,size=shape) for shape in shapes]    \n",
    "        weights_tensor_init = torch.tensor(weights[0], requires_grad=False)\n",
    "        weights_tensor_params = torch.tensor(weights[1], requires_grad=True)\n",
    "        \n",
    "        probs = qc(weights_tensor_init,weights_tensor_params, measurement_qubits=measure_qubits)\n",
    "\n",
    "    else:\n",
    "        weights = [np.random.uniform(-np.pi,np.pi,size=shape) for shape in shapes]    \n",
    "        weights_tensor_params = torch.tensor(weights, requires_grad=True)\n",
    "\n",
    "        probs = qc(weights_tensor_params, measurement_qubits=measure_qubits)\n",
    "\n",
    "    pi = policy(probs, policy_type=policy_type, n_actions=n_actions, n_qubits=n_qubits)\n",
    "    if clamp is not None:\n",
    "        pi = torch.clamp(pi, clamp, 1)\n",
    "\n",
    "    dist = torch.distributions.Categorical(probs=pi)\n",
    "    \n",
    "    action = dist.sample()\n",
    "    log_prob = dist.log_prob(action)\n",
    "\n",
    "    gradient_no_clamp = np.linalg.norm(compute_gradient(log_prob, weights_tensor_params), 2)\n",
    "    return gradient_no_clamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_zz_operator(n_qubits):\n",
    "    ZZ = qml.PauliZ(0)\n",
    "    for i in range(1, n_qubits):\n",
    "        ZZ = qml.operation.Tensor(ZZ, qml.PauliZ(i))\n",
    "    return ZZ\n",
    "\n",
    "def measure_selection(n_qubits, measure_type, observables):\n",
    "    if measure_type == 'probs':\n",
    "        if observables is None:\n",
    "            return qml.probs(wires=range(n_qubits))\n",
    "        else:\n",
    "            return qml.probs(op=observables, wires=range(n_qubits))\n",
    "    elif measure_type == 'expval':\n",
    "        op = observables if observables is not None else create_zz_operator(n_qubits)\n",
    "        return qml.expval(op=op) \n",
    "    \n",
    "def jerbi_model(n_qubits, n_layers, weight_init, measure_type, observables):\n",
    "\n",
    "    dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "    observables = observables if observables is not None else None\n",
    "    \n",
    "    weight_shapes = {\"params\": (n_layers + 1, n_qubits, 2)}\n",
    "    init_method   = {\"params\": weight_init}\n",
    "\n",
    "    @qml.qnode(dev, interface='torch')\n",
    "    def qnode(inputs, params):\n",
    "        qml.broadcast(qml.Hadamard, wires=range(n_qubits), pattern=\"single\")\n",
    "        for layer in range(n_layers):\n",
    "            for wire in range(n_qubits):\n",
    "                qml.RZ(params[layer][wire][0], wires=wire)\n",
    "                qml.RY(params[layer][wire][1], wires=wire)\n",
    "\n",
    "            qml.broadcast(qml.CNOT, wires=range(n_qubits), pattern=\"chain\")\n",
    "            for wire in range(n_qubits):\n",
    "                qml.RY(inputs[wire], wires=wire)\n",
    "                qml.RZ(inputs[wire], wires=wire)\n",
    "\n",
    "        for wire in range(n_qubits):\n",
    "            qml.RZ(params[-1][wire][0], wires=wire)\n",
    "            qml.RY(params[-1][wire][1], wires=wire)\n",
    "    \n",
    "        return measure_selection(n_qubits, measure_type, observables)\n",
    "\n",
    "    model = qml.qnn.TorchLayer(qnode, weight_shapes=weight_shapes, init_method=init_method)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircuitGenerator(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 n_qubits, \n",
    "                 n_layers,  \n",
    "                 shots, \n",
    "                 weight_init=torch.nn.init.uniform_, \n",
    "                 input_init = torch.nn.init.ones_, \n",
    "                 measure_type = 'probs', \n",
    "                 observables = None):\n",
    "        super(CircuitGenerator, self).__init__()\n",
    "        self.n_qubits = n_qubits                        #number of qubits\n",
    "        self.n_layers = n_layers                        #number of layers\n",
    "        self.shots = shots                              #number of shots\n",
    "        self.measure_type = measure_type                #measure type - 'probs' or 'expval'\n",
    "        self.observables = observables                  #observables if the used wants\n",
    "        self.weight_init = weight_init                  #weight initialization method\n",
    "        self.input_init = input_init                    #input weight initialization method\n",
    "\n",
    "\n",
    "\n",
    "    def jerbi_model(self, input_scaling = False):\n",
    "        \n",
    "        if input_scaling:\n",
    "            self.input_params = Parameter(torch.empty(self.n_layers, self.n_qubits, 2))\n",
    "            self.input_init(self.input_params)\n",
    "        else:\n",
    "            self.input_params = None\n",
    "            \n",
    "        self.q_layers = jerbi_model(n_qubits=self.n_qubits,\n",
    "                                    n_layers=self.n_layers,\n",
    "                                    weight_init = self.weight_init,\n",
    "                                    measure_type=self.measure_type,\n",
    "                                    observables=self.observables)\n",
    "        \n",
    "        return self.q_layers\n",
    "\n",
    "    def jerbi_input(self,inputs):\n",
    "\n",
    "        if self.input_params is not None:\n",
    "            inputs = inputs * self.input_params\n",
    "\n",
    "        outputs = self.q_layers(inputs)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1322505372.py, line 29)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[13], line 29\u001b[0;36m\u001b[0m\n\u001b[0;31m    def\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class PolicyType():\n",
    "    \n",
    "    def __init__(self, n_actions, n_qubits):\n",
    "        self.n_actions = n_actions\n",
    "        self.n_qubits = n_qubits\n",
    "\n",
    "    def raw_contiguous(self,probs):\n",
    "\n",
    "        probs_flatten = probs.flatten()\n",
    "        chunk_size = len(probs_flatten) // self.n_actions\n",
    "        remainder = len(probs_flatten) % self.n_actions\n",
    "\n",
    "        # Initialize the sums list\n",
    "        policy = [0] * self.n_actions\n",
    "\n",
    "        # Iterate over each chunk\n",
    "        for i in range(self.n_actions):\n",
    "            # Calculate the start and end indices of the current chunk\n",
    "            start = i * chunk_size\n",
    "            end = (i + 1) * chunk_size\n",
    "\n",
    "            # Add one more element to the first `remainder` chunks if needed\n",
    "            if i < remainder:\n",
    "                end += 1\n",
    "\n",
    "            # Sum the elements in the current chunk\n",
    "            policy[i] = sum(probs_flatten[start:end])\n",
    "\n",
    "        return policy\n",
    "    \n",
    "    def raw_parity(self,probs):\n",
    "\n",
    "        policy = torch.zeros(self.n_actions)\n",
    "        for i in range(len(probs)):\n",
    "            a=[]\n",
    "            for m in range(int(np.log2(self.n_actions))):\n",
    "                if m==0:    \n",
    "                    bitstring = np.binary_repr(i,width=self.n_qubits)\n",
    "                else:\n",
    "                    bitstring = np.binary_repr(i,width=self.n_qubits)[:-m]\n",
    "                \n",
    "                a.append(bitstring.count(\"1\") % 2)\n",
    "            policy[int(\"\".join(str(x) for x in a),2)] += probs[i]\n",
    "\n",
    "        return policy \n",
    "    \n",
    "\n",
    "    def softmax(self,probs,beta):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8.8700e-03, 3.0239e-02, 1.2414e-02, 1.0964e-02, 7.2783e-03, 6.7797e-04,\n",
      "        1.5266e-02, 5.6363e-04, 2.6536e-02, 1.6026e-02, 4.3246e-03, 7.1702e-04,\n",
      "        1.7780e-02, 2.7843e-02, 6.3011e-02, 4.4059e-03, 7.1276e-04, 1.0127e-02,\n",
      "        1.0341e-02, 4.7116e-03, 2.0108e-03, 1.0614e-03, 1.3933e-02, 1.8976e-06,\n",
      "        1.6571e-02, 5.0250e-03, 1.3010e-04, 3.3808e-03, 1.1145e-02, 9.0339e-04,\n",
      "        1.7886e-02, 9.4760e-04, 2.1516e-02, 7.1967e-02, 2.2481e-02, 2.1971e-02,\n",
      "        7.7567e-03, 1.0843e-03, 1.4764e-02, 1.2350e-03, 7.4796e-02, 4.4789e-02,\n",
      "        7.3209e-03, 1.4990e-03, 4.0680e-02, 7.3972e-02, 1.7529e-01, 1.0065e-02,\n",
      "        4.4297e-03, 4.5065e-04, 6.3098e-03, 3.4938e-04, 5.1875e-03, 6.9385e-03,\n",
      "        2.4546e-02, 1.1150e-03, 1.3268e-03, 1.9733e-04, 1.1409e-03, 1.0692e-03,\n",
      "        3.1746e-03, 5.2083e-03, 1.3979e-03, 1.6574e-04],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "n_qubits = 6\n",
    "n_layers = 2\n",
    "shots = 1000\n",
    "\n",
    "weight_init = torch.nn.init.uniform_\n",
    "input_init = torch.nn.init.uniform_\n",
    "# Initialize input parameters with ones\n",
    "\n",
    "# Create a CircuitGenerator instance\n",
    "cg = CircuitGenerator(n_qubits, n_layers, shots, weight_init, input_init)\n",
    "\n",
    "# Get the quantum layer\n",
    "quantum_layer = cg.jerbi_model(input_scaling=False)\n",
    "\n",
    "# Generate some input data\n",
    "inputs = torch.randn(n_qubits)\n",
    "\n",
    "# Pass the input data through the quantum layer\n",
    "outputs = cg.jerbi_input(inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
