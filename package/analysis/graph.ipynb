{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_and_separate_npz_data(root_dir):\n",
    "    # Initialize a dictionary to hold separated data for each tag\n",
    "    separated_data = {\n",
    "        'episode_reward': [],\n",
    "        'loss': [],\n",
    "        'runtime': [],\n",
    "        'params_gradients': [],\n",
    "        'input_params_gradients': []\n",
    "    }\n",
    "\n",
    "    # Walk through all directories and subdirectories in the root directory\n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.npz'):\n",
    "                # Construct full file path\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                \n",
    "                # Load the .npz file if it exists\n",
    "                if os.path.exists(file_path):\n",
    "                    data = np.load(file_path, allow_pickle=True)\n",
    "                    \n",
    "                    # Append the data from this file to the respective lists in the separated data dictionary\n",
    "                    for key in separated_data:\n",
    "                        if key in data:\n",
    "                            # Append each file's data as a new list within the main list\n",
    "                            separated_data[key].append(data[key].tolist())\n",
    "\n",
    "    return separated_data\n",
    "\n",
    "# Usage example:\n",
    "root_directory = os.getcwd()  # Use the current working directory or specify a path\n",
    "separated_data = load_and_separate_npz_data(root_directory)\n",
    "\n",
    "# Now you have all the data separated into lists of lists per tag\n",
    "print(\"Separated Episode Rewards:\", separated_data['episode_reward'])\n",
    "print(\"Separated Losses:\", separated_data['loss'])\n",
    "print(\"Separated Runtimes:\", separated_data['runtime'])\n",
    "print(\"Separated Parameter Gradients:\", separated_data['params_gradients'])\n",
    "print(\"Separated Input Parameter Gradients:\", separated_data['input_params_gradients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class Analysis():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path_to_dir):\n",
    "        self.path = path_to_dir\n",
    "\n",
    "    def load_data(self):\n",
    "        separated_data = {\n",
    "                'episode_reward': [],\n",
    "                'loss': [],\n",
    "                'runtime': [],\n",
    "                'params_gradients': [],\n",
    "                'input_params_gradients': []\n",
    "            }\n",
    "\n",
    "        # Walk through all directories and subdirectories in the root directory\n",
    "        for subdir, dirs, files in os.walk(self.path):\n",
    "            for file in files:\n",
    "                if file.endswith('.npz'):\n",
    "                    # Construct full file path\n",
    "                    file_path = os.path.join(subdir, file)\n",
    "                    \n",
    "                    # Load the .npz file if it exists\n",
    "                    if os.path.exists(file_path):\n",
    "                        data = np.load(file_path, allow_pickle=True)\n",
    "                        \n",
    "                        # Append the data from this file to the respective lists in the separated data dictionary\n",
    "                        for key in separated_data:\n",
    "                            if key in data:\n",
    "                                # Append each file's data as a new list within the main list\n",
    "                                separated_data[key].append(data[key].tolist())\n",
    "\n",
    "        self.data = separated_data\n",
    "       \n",
    "    def get_rewards(self):\n",
    "        return self.data[\"episode_reward\"]\n",
    "    \n",
    "    def get_loss(self):\n",
    "        return self.data[\"loss\"]\n",
    "    \n",
    "    def get_runtime(self):\n",
    "        return self.data[\"runtime\"]\n",
    "    \n",
    "    def get_gradients(self):\n",
    "        return self.data[\"params_gradients\"] \n",
    "    \n",
    "    def get_input_gradients(self):\n",
    "        return self.data[\"input_params_gradients\"]\n",
    "\n",
    "    def get_moving_average(self, window_size = 10):\n",
    "        rewards = self.get_rewards()\n",
    "        moving_averages = []\n",
    "        for reward in rewards:\n",
    "            moving_averages.append(pd.Series(reward).rolling(window_size).mean())\n",
    "        return moving_averages\n",
    "    \n",
    "    def calculate_mean_variance_gradients(self, return_max = False, return_min = False):\n",
    "        gradients = self.get_gradients()\n",
    "        min_length = min([len(gradients[i]) for i in range(len(gradients))])\n",
    "\n",
    "        gradients = [gradients[i][:min_length] for i in range(len(gradients))]\n",
    "\n",
    "        def flatten_gradients(gradients):\n",
    "            for i in range(len(gradients)):\n",
    "                for j in range(len(gradients[i])):\n",
    "                    gradients[i][j] = np.concatenate([lista.flatten() for lista in gradients[i][j]], axis = 0)\n",
    "\n",
    "        flatten_gradients(gradients)\n",
    "\n",
    "        gradients_array = np.array(gradients)\n",
    "\n",
    "        magnitudes_gradients = np.linalg.norm(gradients_array, axis = 2)\n",
    "\n",
    "        mean_magnitudes_gradients = np.mean(magnitudes_gradients, axis = 0)\n",
    "\n",
    "        std_magnitudes_gradients = np.var(magnitudes_gradients, axis = 0)\n",
    "\n",
    "        max_magnitudes_gradients = np.max(magnitudes_gradients, axis = 0)\n",
    "\n",
    "        min_magnitudes_gradients = np.min(magnitudes_gradients, axis = 0)\n",
    "\n",
    "        max_index = np.argmax(gradients_array, axis = 2)\n",
    "\n",
    "        min_index = np.argmin(gradients_array, axis = 2)\n",
    "\n",
    "        if return_max and return_min:\n",
    "            return mean_magnitudes_gradients, std_magnitudes_gradients, max_magnitudes_gradients, max_index, min_magnitudes_gradients, min_index\n",
    "        elif return_max:\n",
    "            return mean_magnitudes_gradients, std_magnitudes_gradients, max_magnitudes_gradients, max_index\n",
    "        elif return_min:\n",
    "            return mean_magnitudes_gradients, std_magnitudes_gradients, min_magnitudes_gradients, min_index\n",
    "        else:\n",
    "            return mean_magnitudes_gradients, std_magnitudes_gradients\n",
    "        \n",
    "    def calculate_mean_variance_input_gradients(self, return_max = False, return_min = False):\n",
    "        gradients = self.get_input_gradients()\n",
    "        min_length = min([len(gradients[i]) for i in range(len(gradients))])\n",
    "\n",
    "        gradients = [gradients[i][:min_length] for i in range(len(gradients))]\n",
    "\n",
    "        def flatten_gradients(gradients):\n",
    "            for i in range(len(gradients)):\n",
    "                for j in range(len(gradients[i])):\n",
    "                    gradients[i][j] = np.concatenate([lista.flatten() for lista in gradients[i][j]], axis = 0)\n",
    "\n",
    "        flatten_gradients(gradients)\n",
    "\n",
    "        gradients_array = np.array(gradients)\n",
    "\n",
    "        magnitudes_gradients = np.linalg.norm(gradients_array, axis = 2)\n",
    "\n",
    "        mean_magnitudes_gradients = np.mean(magnitudes_gradients, axis = 0)\n",
    "\n",
    "        std_magnitudes_gradients = np.var(magnitudes_gradients, axis = 0)\n",
    "\n",
    "        max_magnitudes_gradients = np.max(magnitudes_gradients, axis = 0)\n",
    "\n",
    "        min_magnitudes_gradients = np.min(magnitudes_gradients, axis = 0)\n",
    "\n",
    "        max_index = np.argmax(gradients_array, axis = 2)\n",
    "\n",
    "        min_index = np.argmin(gradients_array, axis = 2)\n",
    "\n",
    "        if return_max and return_min:\n",
    "            return mean_magnitudes_gradients, std_magnitudes_gradients, max_magnitudes_gradients, max_index, min_magnitudes_gradients, min_index\n",
    "        elif return_max:\n",
    "            return mean_magnitudes_gradients, std_magnitudes_gradients, max_magnitudes_gradients, max_index\n",
    "        elif return_min:\n",
    "            return mean_magnitudes_gradients, std_magnitudes_gradients, min_magnitudes_gradients, min_index\n",
    "        else:\n",
    "            return mean_magnitudes_gradients, std_magnitudes_gradients\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_agents(data):\n",
    "    moving_averages = []\n",
    "    for agent in data:\n",
    "        moving_averages.append(moving_average(agent))\n",
    "\n",
    "    all_agents_average = [np.mean(returns) for returns in moving_averages]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
